# -*- coding: utf-8 -*-

"""
@Time    : 2025/12/14 16:54
@File    : assign_categories_tags.py
@Author  : zj
@Description: 

ç¬¬äºŒé˜¶æ®µï¼šä¸ºåšå®¢æ–‡ç« æ™ºèƒ½åˆ†é…åˆ†ç±»ï¼ˆcategoriesï¼‰ä¸æ ‡ç­¾ï¼ˆtagsï¼‰

åŠŸèƒ½è¯´æ˜ï¼š
- åŸºäºé¢„å®šä¹‰çš„ categories.yaml å’Œ tag_vocabulary.yaml ä½“ç³»ï¼Œ
  è°ƒç”¨ DeepSeek å¤§æ¨¡å‹ä¸ºæ¯ç¯‡ Markdown åšå®¢æ–‡ç« ç”Ÿæˆè¯­ä¹‰åŒ¹é…çš„åˆ†ç±»è·¯å¾„ä¸æŠ€æœ¯æ ‡ç­¾ï¼›
- é»˜è®¤é™åˆ¶ï¼šæ¯ç¯‡æ–‡ç« æœ€å¤šåˆ†é… 3 æ¡åˆ†ç±»è·¯å¾„ã€8 ä¸ªæ ‡ç­¾ï¼Œç¡®ä¿ç»“æ„ç®€æ´ï¼›
- æ”¯æŒä¸¤ç§è¿è¡Œæ¨¡å¼ï¼š
    â€¢ æ‰¹é‡æ¨¡å¼ï¼šå¤„ç†æ•´ä¸ªæ–‡ç« ç›®å½•ï¼›
    â€¢ å•æ–‡ä»¶æ¨¡å¼ï¼šé’ˆå¯¹ç‰¹å®šæ–‡ç« ï¼ˆå¦‚ç»¼è¿°ã€å¹´åº¦æ€»ç»“ï¼‰å•ç‹¬å¤„ç†ï¼Œå¹¶å¯ä¸´æ—¶æ”¾å®½æ•°é‡é™åˆ¶ï¼›
- è‡ªåŠ¨æ£€æµ‹å¹¶æŠ¥å‘Šä½¿ç”¨äº†æ–°ç±»åˆ«æˆ–æ–°æ ‡ç­¾çš„æ–‡ç« ï¼Œä¾¿äºäººå·¥å®¡æ ¸ï¼›
- å†…ç½®å¼ºé‡è¯•æœºåˆ¶ï¼ˆæœ€å¤š 5 æ¬¡ï¼‰ä¸è¯¦ç»†çš„ token/è€—æ—¶ç»Ÿè®¡ã€‚

è¾“å…¥ï¼š
  - æ–‡ç« ç›®å½•ï¼ˆæˆ–å•ä¸ª .md æ–‡ä»¶ï¼‰
  - categories.yamlï¼šé¢„å®šä¹‰çš„åˆ†ç±»è·¯å¾„åˆ—è¡¨ï¼ˆå¦‚ ["AI", "å¤§æ¨¡å‹"]ï¼‰
  - tag_vocabulary.yamlï¼šé¢„å®šä¹‰çš„æ ‡å‡†æ ‡ç­¾è¯è¡¨

è¾“å‡ºï¼š
  - ç›´æ¥ä¿®æ”¹æ¯ç¯‡ .md æ–‡ä»¶çš„ front-matterï¼Œå†™å…¥ categories å’Œ tags å­—æ®µ
  - æ§åˆ¶å°è¾“å‡ºå¤„ç†æŠ¥å‘Šï¼šå«æ–°é¡¹æ–‡ç« åˆ—è¡¨ã€æ€»è€—æ—¶ã€æ€» token æ¶ˆè€—ç­‰

å…¸å‹ä½¿ç”¨æ–¹å¼ï¼š

# 1. æ‰¹é‡å¤„ç†ï¼ˆé»˜è®¤é…ç½®ï¼šæœ€å¤š 3 ä¸ªåˆ†ç±»ã€8 ä¸ªæ ‡ç­¾ï¼Œè¯»å–å‰ 3000 å­—ç¬¦ï¼‰
python assign_categories_tags.py ./source/_posts

# 2. å•ç‹¬å¤„ç†æŸç¯‡é•¿æ–‡ï¼ˆå¦‚å¹´åº¦æ€»ç»“ï¼‰ï¼Œä½¿ç”¨å…¨æ–‡å¹¶æ”¾å®½é™åˆ¶
python assign_categories_tags.py \
  --single-file ./source/_posts/2024-year-in-review.md \
  --max-categories 5 \
  --max-tags 15 \
  --max-content-chars -1

# 3. æ‰¹é‡å¤„ç†ä½†ç•¥å¾®æ”¾å®½æ•°é‡é™åˆ¶ï¼ˆè°¨æ…ä½¿ç”¨ï¼Œé¿å…ä½“ç³»æ±¡æŸ“ï¼‰
python assign_categories_tags.py ./source/_posts \
  --max-categories 4 \
  --max-tags 10

# 4. è‡ªå®šä¹‰è¾“å…¥é•¿åº¦ï¼ˆä¾‹å¦‚åªçœ‹å‰ 5000 å­—ç¬¦ï¼‰
python assign_categories_tags.py ./source/_posts --max-content-chars 5000

æ³¨æ„ï¼š
- å¿…é¡»è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY æˆ–åœ¨ä»£ç ä¸­é…ç½® DeepSeek API å¯†é’¥ï¼›
- é¢„å®šä¹‰ä½“ç³»æ–‡ä»¶è·¯å¾„å¯é€šè¿‡ --categories å’Œ --tags å‚æ•°æŒ‡å®šã€‚
"""

import os
import yaml
import argparse
import time
from pathlib import Path
from typing import List, Dict, Set, Tuple

import frontmatter  # pip install python-frontmatter
import openai  # ç¡®ä¿å·²è®¾ç½® OPENAI_API_KEY å’Œ base_url

# ======================
# é…ç½®
# ======================
TEMPERATURE = 0.0
MAX_RETRIES = 5  # å¼ºåˆ¶æˆåŠŸï¼Œæœ€å¤šé‡è¯• 5 æ¬¡

# DeepSeek API é…ç½®ï¼ˆå…¼å®¹ OpenAIï¼‰
MODEL_NAME = "deepseek-reasoner"
os.environ["OPENAI_API_KEY"] = "sk-"
openai.base_url = "https://api.deepseek.com/v1/"
openai.api_key = os.getenv("OPENAI_API_KEY")

# å…¨å±€ç»Ÿè®¡
TOTAL_STATS = {
    "total_time": 0.0,
    "total_requests": 0,
    "total_prompt_tokens": 0,
    "total_completion_tokens": 0,
}


# ======================
# å·¥å…·å‡½æ•°
# ======================

def load_predefined_sets(categories_yaml: str, tags_yaml: str) -> Tuple[Set[Tuple], Set[str]]:
    with open(categories_yaml, 'r', encoding='utf-8') as f:
        cat_data = yaml.safe_load(f)
    with open(tags_yaml, 'r', encoding='utf-8') as f:
        tag_data = yaml.safe_load(f)

    valid_cat_paths = set(tuple(c["path"]) for c in cat_data["categories"])
    valid_tags = set(t["standard_tag"] for t in tag_data["tags"])
    return valid_cat_paths, valid_tags


def collect_markdown_files(posts_dir: str) -> List[Path]:
    return sorted(Path(posts_dir).rglob("*.md"))


def read_article(file_path: Path, max_content_chars: int = 3000) -> Dict:
    """
    è¯»å– Markdown æ–‡ç« ï¼Œæå–æ ‡é¢˜å’Œå†…å®¹é¢„è§ˆã€‚

    Args:
        file_path: æ–‡ç« è·¯å¾„
        max_content_chars: æœ€å¤§è¯»å–å­—ç¬¦æ•°ï¼›è‹¥ä¸º -1ï¼Œåˆ™è¯»å–å…¨æ–‡

    Returns:
        dict: åŒ…å« file, title, preview çš„å­—å…¸
    """
    post = frontmatter.load(str(file_path))
    title = post.get('title', file_path.stem)
    content = post.content

    if max_content_chars == -1:
        # è¯»å…¥æ•´ç¯‡æ–‡ç« 
        preview = " ".join(content.split())  # æ ‡å‡†åŒ–ç©ºç™½
    else:
        # æˆªæ–­å¹¶æ ‡å‡†åŒ–
        preview = " ".join(content[:max_content_chars].split())

    return {
        "file": file_path,
        "title": title,
        "preview": preview
    }


def build_prompt(
        article: Dict,
        all_categories: List[List[str]],
        all_tags: List[str],
        max_categories: int = 3,
        max_tags: int = 8
) -> str:
    # å¯è¯»æ ¼å¼
    readable_cats = ["[" + ", ".join(f'"{part}"' for part in path) + "]" for path in all_categories]
    cats_str = "\n".join([f"- {c}" for c in readable_cats])
    tags_str = "\n".join([f"- {t}" for t in all_tags])

    return f"""ä½ æ˜¯ä¸€ä½åšå®¢å†…å®¹åˆ†ç±»ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ–‡ç« åˆ†é…æœ€åˆé€‚çš„åˆ†ç±»è·¯å¾„å’Œç›¸å…³æŠ€æœ¯æ ‡ç­¾ã€‚

    è¦æ±‚ï¼š
    1. åˆ†ç±»ï¼ˆcategoriesï¼‰ï¼š
       - ä»â€œå¯ç”¨åˆ†ç±»è·¯å¾„â€ä¸­é€‰æ‹© **1 åˆ° {max_categories} æ¡æœ€ç›¸å…³çš„è·¯å¾„**
       - æ¯æ¡è·¯å¾„æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå¦‚ ["å¤§ç±»", "å­ç±»"]
       - å¤šæ¡è·¯å¾„æ—¶ï¼Œè¾“å‡ºä¸ºåˆ—è¡¨çš„åˆ—è¡¨ï¼ˆè§ä¸‹æ–¹ç¤ºä¾‹ï¼‰
    2. æ ‡ç­¾ï¼ˆtagsï¼‰ï¼š
       - ä»â€œå¯ç”¨æ ‡ç­¾â€ä¸­é€‰æ‹© **1 åˆ° {max_tags} ä¸ª**æœ€ç›¸å…³çš„æ ‡å‡†æ ‡ç­¾
    3. å¦‚æœæ–‡ç« æ¶‰åŠå…¨æ–°é¢†åŸŸï¼Œå¯è¿”å›ä½ è®¤ä¸ºåˆç†çš„è·¯å¾„æˆ–æ ‡ç­¾ï¼ˆæˆ‘ä»¬ä¼šäººå·¥å®¡æ ¸ï¼‰
    4. è¾“å‡ºå¿…é¡»æ˜¯çº¯ YAMLï¼Œä»…åŒ…å« categories å’Œ tags ä¸¤ä¸ªå­—æ®µï¼Œä¸è¦ä»»ä½•é¢å¤–å†…å®¹

    ---
    å¯ç”¨åˆ†ç±»è·¯å¾„ï¼ˆæ¯é¡¹æ˜¯ä¸€æ¡å®Œæ•´è·¯å¾„ï¼‰ï¼š
    {cats_str}

    ---
    å¯ç”¨æ ‡ç­¾ï¼š
    {tags_str}

    ---
    æ–‡ç« æ ‡é¢˜: {article['title']}
    å†…å®¹é¢„è§ˆ:
    {article['preview']}

    ---
    è¾“å‡ºç¤ºä¾‹ï¼ˆå¤šæ¡åˆ†ç±»è·¯å¾„ï¼‰ï¼š
    categories:
      - ["æŠ€æœ¯æ•™ç¨‹", "Python"]
      - ["å·¥ç¨‹å®è·µ", "éƒ¨ç½²"]
    tags:
      - Docker
      - Linux
      - CI/CD
    """


def call_llm_with_stats(prompt: str) -> Dict:
    global TOTAL_STATS
    last_error = None

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            start_time = time.time()
            response = openai.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=TEMPERATURE,
                max_tokens=65536,
            )
            duration = time.time() - start_time

            # æå– token ä¿¡æ¯
            usage = response.usage
            prompt_tk = usage.prompt_tokens
            completion_tk = usage.completion_tokens

            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            TOTAL_STATS["total_requests"] += 1
            TOTAL_STATS["total_prompt_tokens"] += prompt_tk
            TOTAL_STATS["total_completion_tokens"] += completion_tk
            TOTAL_STATS["total_time"] += duration

            print(f"â±ï¸  LLM Call | è€—æ—¶: {duration:.2f}s | è¾“å…¥: {prompt_tk} tk | è¾“å‡º: {completion_tk} tk")

            # è§£æè¾“å‡º
            text = response.choices[0].message.content.strip()
            if text.startswith("```"):
                text = "\n".join(text.split("\n")[1:-1])
            data = yaml.safe_load(text)

            return {
                "categories": data.get("categories", []),
                "tags": [str(t).strip() for t in data.get("tags", []) if t]
            }

        except Exception as e:
            last_error = e
            wait_time = min(2 ** attempt, 10)
            print(f"âš ï¸  ç¬¬ {attempt}/{MAX_RETRIES} æ¬¡è°ƒç”¨å¤±è´¥: {e}. ç­‰å¾… {wait_time}s...")
            time.sleep(wait_time)

    # æ‰€æœ‰é‡è¯•å¤±è´¥
    raise RuntimeError(f"LLM è°ƒç”¨å½»åº•å¤±è´¥ï¼ˆ{MAX_RETRIES} æ¬¡é‡è¯•åä»å¤±è´¥ï¼‰: {last_error}")


def normalize_categories(raw_cats, max_paths: int = 3):
    """å°† LLM è¿”å›çš„ categories ç»Ÿä¸€è½¬ä¸º List[List[str]]ï¼Œæœ€å¤šä¿ç•™ max_paths æ¡è·¯å¾„"""
    if not raw_cats:
        return []

    # ç¡®ä¿æ˜¯åˆ—è¡¨ç±»å‹
    if not isinstance(raw_cats, list):
        return []

    # æƒ…å†µ1: ["AI", "å¤§æ¨¡å‹"] â†’ å•æ¡è·¯å¾„ï¼ˆæ‰å¹³åˆ—è¡¨ï¼‰
    if len(raw_cats) > 0 and isinstance(raw_cats[0], str):
        # åˆå¹¶ä¸ºä¸€æ¡è·¯å¾„ï¼ˆå³ä½¿ max_paths > 1ï¼Œä¹Ÿåªæœ‰ä¸€æ¡ï¼‰
        return [list(raw_cats)]

    # æƒ…å†µ2: [["AI", "å¤§æ¨¡å‹"], ["å·¥ç¨‹", "éƒ¨ç½²"]] â†’ å¤šæ¡è·¯å¾„
    if len(raw_cats) > 0 and isinstance(raw_cats[0], list):
        # åªå–å‰ max_paths æ¡ï¼Œæ¯æ¡è½¬ä¸º list[str]
        return [list(path) for path in raw_cats[:max_paths] if isinstance(path, list)]

    # å…¶ä»–å¼‚å¸¸æ ¼å¼ï¼ˆå¦‚æ··åˆã€None ç­‰ï¼‰
    return []


def write_frontmatter(file_path: Path, new_cats, new_tags: List[str]):
    # ä¸æŒ‡å®š new_cats ç±»å‹ï¼Œå› ä¸ºå¯èƒ½æ˜¯ List[str] æˆ– List[List[str]]
    post = frontmatter.load(str(file_path))
    post['categories'] = new_cats
    post['tags'] = new_tags
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(frontmatter.dumps(post))


# ======================
# ä¸»é€»è¾‘
# ======================

def main(
        posts_dir: str = None,
        single_file: str = None,
        categories_yaml: str = "categories.yaml",
        tags_yaml: str = "tag_vocabulary.yaml",
        max_categories: int = 3,
        max_tags: int = 8,
        max_content_chars: int = 3000,  # â† æ–°å¢å‚æ•°
):
    print("ğŸ” åŠ è½½é¢„å®šä¹‰ä½“ç³»...")
    valid_cat_paths, valid_tags = load_predefined_sets(categories_yaml, tags_yaml)
    all_cat_list = [list(p) for p in valid_cat_paths]
    all_tag_list = list(valid_tags)
    print(f"âœ… å…± {len(all_cat_list)} ä¸ªåˆ†ç±»è·¯å¾„ï¼Œ{len(all_tag_list)} ä¸ªæ ‡å‡†æ ‡ç­¾")

    # ç¡®å®šè¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    if single_file:
        file_path = Path(single_file)
        if not file_path.exists():
            raise FileNotFoundError(f"æŒ‡å®šçš„å•ä¸ªæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        md_files = [file_path]
        print(f"ğŸ¯ å•æ–‡ä»¶æ¨¡å¼: {file_path.name}")
    elif posts_dir:
        md_files = collect_markdown_files(posts_dir)
        print(f"ğŸ“ æ‰¹é‡æ¨¡å¼: å…±æ‰¾åˆ° {len(md_files)} ç¯‡æ–‡ç« \n")
    else:
        raise ValueError("å¿…é¡»æŒ‡å®š posts_dir æˆ– single_file")

    articles_with_new_items = []

    for i, file_path in enumerate(md_files, 1):
        if single_file:
            print(f"\nğŸ¯ å¤„ç†å•ç¯‡æ–‡ç« : {file_path.name}")
        else:
            print(f"\n[{i}/{len(md_files)}] å¤„ç†: {file_path.name}")

        try:
            # â† ä¼ å…¥ max_content_chars
            art = read_article(file_path, max_content_chars=max_content_chars)
            prompt = build_prompt(
                art,
                all_cat_list,
                all_tag_list,
                max_categories=max_categories,
                max_tags=max_tags
            )
            result = call_llm_with_stats(prompt)

            assigned_cats = normalize_categories(result.get("categories"), max_paths=max_categories)
            assigned_tags_raw = result.get("tags", [])
            assigned_tags = [str(t).strip() for t in assigned_tags_raw if t][:max_tags]

            # æ£€æŸ¥æ–°ç±»åˆ«/æ ‡ç­¾
            has_new_cat = any(
                isinstance(path, list) and tuple(path) not in valid_cat_paths
                for path in assigned_cats
            )
            new_tags_in_result = [t for t in assigned_tags if t not in valid_tags]
            has_new_tag = len(new_tags_in_result) > 0

            if has_new_cat or has_new_tag:
                articles_with_new_items.append({
                    "file": str(file_path),
                    "title": art["title"],
                    "new_categories": assigned_cats if has_new_cat else None,
                    "new_tags": new_tags_in_result
                })

            write_frontmatter(file_path, assigned_cats, assigned_tags)
            print(f"  â†’ å†™å…¥ categories: {assigned_cats}")
            print(f"  â†’ å†™å…¥ tags: {assigned_tags}")

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            continue

    # === æŠ¥å‘Š ===
    print("\n" + "=" * 60)
    print("ğŸ“Š å…¨å±€ç»Ÿè®¡:")
    print(f"  â€¢ æ€»è€—æ—¶: {TOTAL_STATS['total_time']:.2f} ç§’")
    print(f"  â€¢ æ€»è¯·æ±‚æ•°: {TOTAL_STATS['total_requests']}")
    print(f"  â€¢ æ€»è¾“å…¥ tokens: {TOTAL_STATS['total_prompt_tokens']}")
    print(f"  â€¢ æ€»è¾“å‡º tokens: {TOTAL_STATS['total_completion_tokens']}")
    print("=" * 60)

    if articles_with_new_items:
        print(f"\nâš ï¸  å‘ç° {len(articles_with_new_items)} ç¯‡æ–‡ç« ä½¿ç”¨äº†æ–°çš„ç±»åˆ«æˆ–æ ‡ç­¾ï¼Œéœ€äººå·¥å®¡æ ¸ï¼š\n")
        for item in articles_with_new_items:
            print(f"ğŸ“„ {item['file']}")
            if item['new_categories']:
                print(f"   æ–°ç±»åˆ«: {item['new_categories']}")
            if item['new_tags']:
                print(f"   æ–°æ ‡ç­¾: {item['new_tags']}")
            print()
    else:
        print("\nâœ… æ‰€æœ‰æ–‡ç« å‡ä½¿ç”¨äº†é¢„å®šä¹‰ä½“ç³»ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="ä¸ºåšå®¢æ–‡ç« åˆ†é…åˆ†ç±»å’Œæ ‡ç­¾ï¼ˆæ”¯æŒæ‰¹é‡æˆ–å•æ–‡ä»¶ï¼‰"
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("posts_dir", nargs="?", help="åšå®¢æ–‡ç« ç›®å½•ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰")
    group.add_argument("--single-file", type=str, help="å•ä¸ª Markdown æ–‡ä»¶è·¯å¾„ï¼ˆå•æ–‡ä»¶æ¨¡å¼ï¼‰")

    parser.add_argument("--categories", default="categories.yaml", help="åˆ†ç±»å®šä¹‰æ–‡ä»¶")
    parser.add_argument("--tags", default="tag_vocabulary.yaml", help="æ ‡ç­¾è¯è¡¨æ–‡ä»¶")
    parser.add_argument("--max-categories", type=int, default=3, help="æœ€å¤šåˆ†ç±»è·¯å¾„æ•°ï¼ˆé»˜è®¤: 3ï¼‰")
    parser.add_argument("--max-tags", type=int, default=8, help="æœ€å¤šæ ‡ç­¾æ•°ï¼ˆé»˜è®¤: 8ï¼‰")
    parser.add_argument(
        "--max-content-chars",
        type=int,
        default=3000,
        help="æ¯ç¯‡æ–‡ç« æœ€å¤§è¯»å–å­—ç¬¦æ•°ï¼ˆé»˜è®¤: 3000ï¼›è®¾ä¸º -1 è¡¨ç¤ºè¯»å–å…¨æ–‡ï¼‰"
    )

    args = parser.parse_args()

    main(
        posts_dir=args.posts_dir,
        single_file=args.single_file,
        categories_yaml=args.categories,
        tags_yaml=args.tags,
        max_categories=args.max_categories,
        max_tags=args.max_tags,
        max_content_chars=args.max_content_chars,  # â† ä¼ å…¥æ–°å‚æ•°
    )
